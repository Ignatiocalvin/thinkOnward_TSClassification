{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 GB\n",
      "Cached memory: 0.00 GB\n",
      "Total memory: 12.00 GB\n",
      "Unused memory: 12.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import print_gpu_memory\n",
    "print_gpu_memory()\n",
    "import os\n",
    "import sys\n",
    "base_path = r\"C:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\"\n",
    "data_path = r\"\\data\\building-instinct-starter-notebook\\Starter notebook\"\n",
    "sys.path.append(base_path+data_path)\n",
    "sys.path.append(base_path+\"\\kai\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "# from utils import (calculate_average_hourly_energy_consumption, train_model, get_pred, calculate_hierarchical_f1_score,\n",
    "# sample_submission_generator)\n",
    "from preprocessing import Preprocessor\n",
    "# file_path = base_path + data_path + r\"\\building-instinct-train-data\"\n",
    "# df_features = Preprocessor.load_standard_df(file_path)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/data_9000.parquet', engine='pyarrow')\n",
    "\n",
    "# df_loaded_1 = pd.read_parquet(base_path + '/preprocessed_data/data_3000.parquet', engine='pyarrow')\n",
    "# df_loaded_2 = pd.read_parquet(base_path + '/preprocessed_data/data_6000.parquet', engine='pyarrow')\n",
    "# df_loaded_3 = pd.read_parquet(base_path + '/preprocessed_data/data_9000.parquet', engine='pyarrow')\n",
    "\n",
    "# df_features = pd.concat([df_loaded_1, df_loaded_2, df_loaded_3], axis=0)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "\n",
    "df_features = pd.read_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "df_features.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import TargetPreprocessor\n",
    "load_filepath_labels = os.path.join(base_path + data_path,'building-instinct-train-label', 'train_label.parquet')#path to the train label file\n",
    "df_targets = pd.read_parquet(load_filepath_labels, engine='pyarrow')\n",
    "df_targets.sort_index(inplace=True)\n",
    "\n",
    "df_targets_res = df_targets[df_targets.building_stock_type == \"residential\"].filter(like='_res').copy()\n",
    "df_targets_com = df_targets[df_targets.building_stock_type == \"commercial\"].filter(like='_com').copy()\n",
    "target_preprocessor = TargetPreprocessor()\n",
    "df_targets_res, association_dict_res, encoder_res = target_preprocessor.preprocess_res(df_targets_res)\n",
    "df_targets_com, association_dict_com, encoder_com = target_preprocessor.preprocess_com(df_targets_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = df_features.index.intersection(df_targets_com.index)\n",
    "# Filter the data\n",
    "X_com = df_features[df_features.index.isin(common_indices)]\n",
    "X_com = torch.tensor(X_com.values, dtype=torch.float32)\n",
    "y_com = df_targets_com[df_targets_com.index.isin(common_indices)]\n",
    "y_com = torch.tensor(y_com.values, dtype=torch.float32)\n",
    "\n",
    "X_res = df_features[df_features.index.isin(df_targets_res.index)]\n",
    "X_res = torch.tensor(X_res.values, dtype=torch.float32)\n",
    "y_res = df_targets_res[df_targets_res.index.isin(df_features.index)]\n",
    "y_res = torch.tensor(y_res.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992323346090601\n",
      "[[765   2]\n",
      " [  9 664]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = df_features, df_targets[\"building_stock_type\"].map({\"residential\": 0, \"commercial\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = Pipeline([('preprocessor', ColumnTransformer([\n",
    "            ('scaler', StandardScaler(), X.columns),\n",
    "            ('encoder', OneHotEncoder(), [])\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "df_test.sort_index(inplace=True)\n",
    "\n",
    "clf = Pipeline([('preprocessor', ColumnTransformer([\n",
    "            ('scaler', StandardScaler(), X.columns),\n",
    "            ('encoder', OneHotEncoder(), [])\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(df_test)\n",
    "df_test[\"building_stock_type\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## com model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from models import MultiTaskLSTM, CustomLoss, TimeSeriesDataset\n",
    "# from datetime import datetime\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # model parameters\n",
    "# batch_size = 16\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# input_size, sequence_length = 1, X_com.shape[1]\n",
    "# num_classes_categorical = y_com.shape[1]\n",
    "# hidden_size = 64\n",
    "# num_epochs = 20\n",
    "\n",
    "# weight_numerical = 10e-4\n",
    "# weight_categorical = 1.0\n",
    "\n",
    "# best_combined_loss = float('inf')\n",
    "# checkpoint_filename = base_path+ f'/kai/checkpoints/model_checkpoint_{datetime.now().strftime(\"%m_%d_%H_%M\")}.pth.tar'\n",
    "\n",
    "# # create dataloaders\n",
    "# dataloader_com = DataLoader(TimeSeriesDataset(X_com, y_com), batch_size=batch_size, shuffle=True)\n",
    "# dataloader_res = DataLoader(TimeSeriesDataset(X_res, y_res), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "# model = model.to(device)\n",
    "# criterion = CustomLoss(association_dict_com)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     for X_batch, y_categorical_batch in dataloader_com:\n",
    "#         X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "#         X_batch = X_batch.to(device)\n",
    "#         y_categorical_batch = y_categorical_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         categorical_pred = model(X_batch)\n",
    "#         loss, loss_numerical, loss_categorical = criterion(categorical_pred, y_categorical_batch)\n",
    "        \n",
    "#         # Combine losses with adjusted weights\n",
    "#         combined_loss = weight_numerical * loss_numerical + weight_categorical * loss_categorical\n",
    "\n",
    "#         combined_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "#                   f'Total Loss: {loss.item():.4f}, '\n",
    "#                   f'Numerical Loss: {loss_numerical.item():.4f}, '\n",
    "#                   f'Categorical Loss: {loss_categorical.item():.4f}, '\n",
    "#                   f'Combined Loss: {combined_loss.item():.4f}, '\n",
    "#                   f'weights: {weight_numerical:.4f}, {weight_categorical:.4f}')\n",
    "    \n",
    "#     if combined_loss.item() < best_combined_loss:\n",
    "#         torch.save({'epoch': epoch + 1,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'loss': combined_loss.item(),}, checkpoint_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAI\\AppData\\Local\\Temp\\ipykernel_4584\\3095246467.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2700e+00, 1.9236e+03, 3.4095e+02, 3.3733e+02, 8.6536e+00, 1.8160e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2806e+00, 1.9351e+03, 3.4299e+02, 3.3937e+02, 8.6881e+00, 1.8266e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2486e+00, 1.9773e+03, 3.5050e+02, 3.4711e+02, 8.7141e+00, 1.8562e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2377e+00, 1.9897e+03, 3.5269e+02, 3.4937e+02, 8.7197e+00, 1.8646e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2713e+00, 1.9247e+03, 3.4115e+02, 3.3754e+02, 8.6578e+00, 1.8171e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2689e+00, 1.9227e+03, 3.4079e+02, 3.3717e+02, 8.6502e+00, 1.8151e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2645e+00, 1.9188e+03, 3.4009e+02, 3.3648e+02, 8.6354e+00, 1.8114e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2378e+00, 1.9895e+03, 3.5266e+02, 3.4934e+02, 8.7196e+00, 1.8645e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2379e+00, 1.9894e+03, 3.5263e+02, 3.4932e+02, 8.7195e+00, 1.8644e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2807e+00, 1.9373e+03, 3.4338e+02, 3.3977e+02, 8.6917e+00, 1.8284e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2803e+00, 1.9387e+03, 3.4364e+02, 3.4003e+02, 8.6936e+00, 1.8295e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "tensor([2.0000e+00, 2.0060e+03, 7.3000e+01, 6.7000e+01, 7.5000e+00, 1.2000e+01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from models import MultiTaskLSTM, CustomLoss, TimeSeriesDataset\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size, input_size, sequence_length, hidden_size, num_classes_categorical = 16, 1, X_com.shape[1], 64, y_com.shape[1]\n",
    "checkpoint_filename = base_path+ f'/kai/checkpoints/com_model_checkpoint_08_06_14_49.pth.tar'\n",
    "\n",
    "dataloader_com = DataLoader(TimeSeriesDataset(X_com, y_com), batch_size=batch_size, shuffle=True)\n",
    "model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "for X_batch, y_categorical_batch in dataloader_com:\n",
    "    for i in [0, 1]:\n",
    "        _X_batch = X_batch[:, :].view(X_batch.shape[0], sequence_length, input_size)\n",
    "        _X_batch = _X_batch.to(device)\n",
    "        categorical_pred = model.predict(_X_batch, association_dict_com)\n",
    "        print(categorical_pred)\n",
    "        print(y_categorical_batch[i, :])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the original com df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in.number_of_stories_com</th>\n",
       "      <th>in.vintage_com</th>\n",
       "      <th>in.tstat_clg_sp_f..f_com</th>\n",
       "      <th>in.tstat_htg_sp_f..f_com</th>\n",
       "      <th>in.weekday_opening_time..hr_com</th>\n",
       "      <th>in.weekday_operating_hours..hr_com</th>\n",
       "      <th>in.comstock_building_type_group_com</th>\n",
       "      <th>in.heating_fuel_com</th>\n",
       "      <th>in.hvac_category_com</th>\n",
       "      <th>in.ownership_type_com</th>\n",
       "      <th>in.wall_construction_type_com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1970 to 1979</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    in.number_of_stories_com in.vintage_com  in.tstat_clg_sp_f..f_com  \\\n",
       "0                          2   1980 to 1989                        80   \n",
       "1                          2    Before 1946                        80   \n",
       "2                          2    Before 1946                        80   \n",
       "3                          2   1970 to 1979                        80   \n",
       "4                          2   1980 to 1989                        80   \n",
       "5                          2    Before 1946                        80   \n",
       "6                          2    Before 1946                        80   \n",
       "7                          2   1980 to 1989                        80   \n",
       "8                          2   1980 to 1989                        80   \n",
       "9                          2    Before 1946                        80   \n",
       "10                         2   1980 to 1989                        80   \n",
       "11                         2   1980 to 1989                        80   \n",
       "12                         2   1980 to 1989                        80   \n",
       "13                         2   1980 to 1989                        80   \n",
       "14                         2    Before 1946                        80   \n",
       "15                         2    Before 1946                        80   \n",
       "\n",
       "    in.tstat_htg_sp_f..f_com in.weekday_opening_time..hr_com  \\\n",
       "0                         72                            8.75   \n",
       "1                         72                            8.75   \n",
       "2                         72                            8.75   \n",
       "3                         72                            8.75   \n",
       "4                         72                            8.75   \n",
       "5                         72                            8.75   \n",
       "6                         72                            8.75   \n",
       "7                         72                            8.75   \n",
       "8                         72                            8.75   \n",
       "9                         72                            8.75   \n",
       "10                        72                            8.75   \n",
       "11                        72                            8.75   \n",
       "12                        72                            8.75   \n",
       "13                        72                            8.75   \n",
       "14                        72                            8.75   \n",
       "15                        72                            8.75   \n",
       "\n",
       "   in.weekday_operating_hours..hr_com in.comstock_building_type_group_com  \\\n",
       "0                               18.75                          Mercantile   \n",
       "1                               18.25                              Office   \n",
       "2                               18.25                          Mercantile   \n",
       "3                                18.5                          Mercantile   \n",
       "4                               18.75                          Mercantile   \n",
       "5                               18.25                              Office   \n",
       "6                               18.25                              Office   \n",
       "7                               18.75                          Mercantile   \n",
       "8                               18.75                          Mercantile   \n",
       "9                                18.0                              Office   \n",
       "10                              18.75                          Mercantile   \n",
       "11                              18.75                          Mercantile   \n",
       "12                              18.75                          Mercantile   \n",
       "13                              18.75                          Mercantile   \n",
       "14                              18.25                          Mercantile   \n",
       "15                              18.25                          Mercantile   \n",
       "\n",
       "   in.heating_fuel_com in.hvac_category_com in.ownership_type_com  \\\n",
       "0          Electricity  Small Packaged Unit                leased   \n",
       "1          Electricity  Small Packaged Unit                leased   \n",
       "2          Electricity  Small Packaged Unit                leased   \n",
       "3          Electricity  Small Packaged Unit                leased   \n",
       "4          Electricity  Small Packaged Unit                leased   \n",
       "5          Electricity  Small Packaged Unit                leased   \n",
       "6          Electricity  Small Packaged Unit                leased   \n",
       "7          Electricity  Small Packaged Unit                leased   \n",
       "8          Electricity  Small Packaged Unit                leased   \n",
       "9          Electricity  Small Packaged Unit                leased   \n",
       "10         Electricity  Small Packaged Unit                leased   \n",
       "11         Electricity  Small Packaged Unit                leased   \n",
       "12         Electricity  Small Packaged Unit                leased   \n",
       "13         Electricity  Small Packaged Unit                leased   \n",
       "14         Electricity  Small Packaged Unit                leased   \n",
       "15         Electricity  Small Packaged Unit                leased   \n",
       "\n",
       "   in.wall_construction_type_com  \n",
       "0                    SteelFramed  \n",
       "1                    SteelFramed  \n",
       "2                    SteelFramed  \n",
       "3                    SteelFramed  \n",
       "4                    SteelFramed  \n",
       "5                    SteelFramed  \n",
       "6                    SteelFramed  \n",
       "7                    SteelFramed  \n",
       "8                    SteelFramed  \n",
       "9                    SteelFramed  \n",
       "10                   SteelFramed  \n",
       "11                   SteelFramed  \n",
       "12                   SteelFramed  \n",
       "13                   SteelFramed  \n",
       "14                   SteelFramed  \n",
       "15                   SteelFramed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from postprocessing import inverse_process\n",
    "arr_df = inverse_process(categorical_pred, encoder_com) # todo: standardize the target numerical columns in preprocessing\n",
    "display(arr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(654, 35040)\n"
     ]
    }
   ],
   "source": [
    "# file_path = base_path + data_path + r\"\\building-instinct-test-data\"\n",
    "# df_features = Preprocessor.load_standard_df(file_path)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "\n",
    "# df_test = pd.read_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "# df_test.sort_index(inplace=True)\n",
    "\n",
    "# TODO: clf that predicts com or res\n",
    "# then filter by com & res\n",
    "df_test_com = df_test[df_test.building_stock_type == 1]\n",
    "# df_test = df_test[df_test.index.isin(df_features.index)]\n",
    "# X_test_com = torch.tensor(df_test.values, dtype=torch.float32)\n",
    "# X_test_com = X_test_com.to(device)\n",
    "print(df_test_com[df_test_com.columns.difference([\"building_stock_type\"])].shape)\n",
    "X_test_com, y_pred_com = torch.tensor(df_test_com[df_test_com.columns.difference([\"building_stock_type\"])].values, dtype=torch.float32), df_test_com[\"building_stock_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAI\\AppData\\Local\\Temp\\ipykernel_4584\\3946375991.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 3.22 GB\n",
      "Cached memory: 3.23 GB\n",
      "Total memory: 12.00 GB\n",
      "Unused memory: 8.78 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:11<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "def free_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "free_gpu_memory()\n",
    "model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "model = model.to(device)\n",
    "criterion = CustomLoss(association_dict_com)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "checkpoint_filename = base_path+ f'/kai/checkpoints/com_model_checkpoint_08_06_14_49.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "best_loss = checkpoint['loss']\n",
    "\n",
    "predictions = []\n",
    "dataloader = DataLoader(TimeSeriesDataset(X_test_com, torch.zeros(X_test_com.shape[0], y_com.shape[1])), batch_size=16, shuffle=False)\n",
    "\n",
    "print_gpu_memory()\n",
    "for X_batch, y_categorical_batch in tqdm(dataloader):\n",
    "    model.eval()\n",
    "    _X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "    _X_batch = _X_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        categorical_pred = model.predict(_X_batch, association_dict_com)\n",
    "    predictions.append(categorical_pred.cpu())\n",
    "    del _X_batch, categorical_pred\n",
    "    free_gpu_memory()\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "arr_df_com = inverse_process(predictions, encoder_com)\n",
    "arr_df_com.index = df_test_com.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "['1980 to 1989' '1960 to 1969' 'Before 1946' '1970 to 1979' '1946 to 1959']\n",
      "[80]\n",
      "[72]\n",
      "[8.75]\n",
      "[18.75 18.5 18.25 18.0]\n",
      "['Mercantile' 'Office']\n",
      "['Electricity']\n",
      "['Small Packaged Unit']\n",
      "['leased']\n",
      "['SteelFramed']\n"
     ]
    }
   ],
   "source": [
    "for col in arr_df_com.columns:\n",
    "    print(arr_df_com[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3900, 35040]) torch.Size([3900, 38])\n",
      "{'in.geometry_building_type_recs': [6, 7, 8, 9, 10], 'in.geometry_foundation_type': [11, 12, 13, 14, 15, 16], 'in.geometry_wall_type': [17, 18, 19, 20], 'in.heating_fuel': [21, 22, 23, 24, 25, 26], 'in.roof_material': [27, 28, 29, 30, 31, 32, 33], 'in.tenure': [34, 35], 'in.vacancy_status': [36, 37]}\n",
      "{'in.comstock_building_type_group': [6, 7, 8, 9, 10, 11, 12], 'in.heating_fuel': [13, 14, 15, 16, 17], 'in.hvac_category': [18, 19, 20, 21, 22], 'in.ownership_type': [23, 24, 25, 26, 27], 'in.wall_construction_type': [28, 29, 30, 31]}\n",
      "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(X_res.shape, y_res.shape)\n",
    "print(association_dict_res)\n",
    "print(association_dict_com)\n",
    "print(y_res[:, [6, 7, 8, 9, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define custom loss function\n",
    "class CustomLoss_res(nn.Module):\n",
    "    def __init__(self, column_groups):\n",
    "        super(CustomLoss_res, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.column_groups = column_groups  # Dictionary mapping attribute prefixes to column indices\n",
    "        self.end_numerical = int(min([min(v) for v in self.column_groups.values()]))\n",
    "    \n",
    "    def forward(self, categorical_pred, categorical_true):\n",
    "        # Compute numerical loss (assuming the first few columns are numerical)\n",
    "        loss_numerical = self.mse_loss(categorical_pred[:, :self.end_numerical], categorical_true[:, :self.end_numerical])\n",
    "\n",
    "        # Initialize categorical loss\n",
    "        loss_categorical = 0.0\n",
    "        \n",
    "        # For each attribute group, compute the cross-entropy loss\n",
    "        for attr, indices in self.column_groups.items():\n",
    "            # Extract logits for the current attribute\n",
    "            logits = categorical_pred[:, indices]\n",
    "            \n",
    "            # Extract the true labels for the current attribute\n",
    "            # Convert one-hot encoding to class indices\n",
    "            true_labels = torch.argmax(categorical_true[:, indices], dim=1)\n",
    "            \n",
    "            # Compute cross-entropy loss for the current attribute\n",
    "            loss_categorical += F.cross_entropy(logits, true_labels)\n",
    "\n",
    "        total_loss = loss_numerical + loss_categorical\n",
    "        return total_loss, loss_numerical, loss_categorical   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from models import MultiTaskLSTM, CustomLoss, TimeSeriesDataset\n",
    "# from datetime import datetime\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # model parameters\n",
    "# batch_size = 16\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# input_size, sequence_length = 1, X_res.shape[1]\n",
    "# num_classes_categorical = y_res.shape[1]\n",
    "# hidden_size = 64\n",
    "# num_epochs = 20\n",
    "\n",
    "# weight_numerical = 10e-4\n",
    "# weight_categorical = 1.0\n",
    "\n",
    "# best_combined_loss = float('inf')\n",
    "# checkpoint_filename = base_path+ f'/kai/checkpoints/res_model_checkpoint_{datetime.now().strftime(\"%m_%d_%H_%M\")}.pth.tar'\n",
    "\n",
    "# # create dataloaders\n",
    "# # dataloader_com = DataLoader(TimeSeriesDataset(X_com, y_com), batch_size=batch_size, shuffle=True)\n",
    "# dataloader_res = DataLoader(TimeSeriesDataset(X_res, y_res), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "# model = model.to(device)\n",
    "# criterion_res = CustomLoss_res(association_dict_res)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     for X_batch, y_categorical_batch in dataloader_res:\n",
    "#         X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "#         X_batch = X_batch.to(device)\n",
    "#         y_categorical_batch = y_categorical_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         categorical_pred = model(X_batch)\n",
    "#         loss, loss_numerical, loss_categorical = criterion_res(categorical_pred, y_categorical_batch)\n",
    "        \n",
    "#         # Combine losses with adjusted weights\n",
    "#         combined_loss = weight_numerical * loss_numerical + weight_categorical * loss_categorical\n",
    "\n",
    "#         combined_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "#                   f'Total Loss: {loss.item():.4f}, '\n",
    "#                   f'Numerical Loss: {loss_numerical.item():.4f}, '\n",
    "#                   f'Categorical Loss: {loss_categorical.item():.4f}, '\n",
    "#                   f'Combined Loss: {combined_loss.item():.4f}, '\n",
    "#                   f'weights: {weight_numerical:.4f}, {weight_categorical:.4f}')\n",
    "    \n",
    "#     if combined_loss.item() < best_combined_loss:\n",
    "#         torch.save({'epoch': epoch + 1,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'loss': combined_loss.item(),}, checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo postprocessing + analysis of res and com labels in general! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_closest_values(predictions, possible_values):\n",
    "    \"\"\"\n",
    "    Map predicted values to the closest possible values.\n",
    "\n",
    "    Args:\n",
    "    - predictions (list of lists): The predicted values.\n",
    "    - possible_values (dict): A dictionary where keys are column names and values are lists of possible values.\n",
    "\n",
    "    Returns:\n",
    "    - mapped_predictions (list of lists): The predictions mapped to the closest possible values.\n",
    "    \"\"\"\n",
    "    def closest_value(predicted, possible):\n",
    "        return possible[np.argmin((np.array(possible) - predicted)**2)]\n",
    "    \n",
    "    mapped_predictions = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        mapped_row = []\n",
    "        for col_name, pred_value in zip(possible_values.keys(), prediction):\n",
    "            mapped_value = closest_value(pred_value, possible_values[col_name])\n",
    "            mapped_row.append(mapped_value)\n",
    "        mapped_predictions.append(mapped_row)\n",
    "    \n",
    "    return mapped_predictions\n",
    "\n",
    "def inverse_process_res(prediction, encoder):\n",
    "    prediction = prediction.cpu().detach().numpy()\n",
    "\n",
    "    # Possible values for each column\n",
    "    possible_values = {\n",
    "        'in.bedrooms_res': [3, 2, 1, 4, 5],\n",
    "        'in.cooling_setpoint_res': [68, 75, 72, 70, 78, 80, 60, 65, 76, 67, 62],\n",
    "        'in.heating_setpoint_res': [75, 72, 68, 70, 62, 55, 65, 78, 76, 67, 60, 80],\n",
    "        'in.geometry_floor_area_res': [1749,  874, 1249,  624, 2249, 4000, 2749, 3499,  249],\n",
    "        'in.income_res': [109999,  12499,  64999,  89999,  42499,  22499,  47499, 169999, 129999,\n",
    "                            200000,  37499,  54999,  32499,  10000, 189999,  74999,  17499,  27499,\n",
    "                            149999],\n",
    "        'in.vintage_res': [1940, 1975, 1985, 1945, 1995, 1955, 1965, 2005, 2015]\n",
    "    }\n",
    "    mapped_predictions = prediction.copy()\n",
    "    # Map the predictions\n",
    "    mapped_predictions_1 = map_to_closest_values(prediction[:, :6], possible_values)\n",
    "    mapped_predictions_2 = encoder.inverse_transform(prediction[:, 6:])\n",
    "\n",
    "    mapped_predictions = np.concatenate((mapped_predictions_1, mapped_predictions_2), axis=1)\n",
    "    cols = ['in.bedrooms_res', 'in.cooling_setpoint_res', 'in.heating_setpoint_res',\n",
    "            'in.geometry_floor_area_res', 'in.income_res', 'in.vintage_res',\n",
    "            'in.geometry_building_type_recs_res', 'in.geometry_foundation_type_res', \n",
    "            'in.geometry_wall_type_res', 'in.heating_fuel_res', 'in.roof_material_res',\n",
    "            'in.tenure_res', 'in.vacancy_status_res']\n",
    "    \n",
    "    mapped_df = pd.DataFrame(mapped_predictions, columns=cols)\n",
    "\n",
    "    vintage_mapping = {1940:'<1940', 1945:'1940s', 1955:'1950s', 1965:'1960s',\n",
    "                           1975:'1970s', 1985:'1980s', 1995:'1990s', 2005:'2000s', 2015:'2010s'}\n",
    "    mapped_df['in.vintage_res'] = mapped_df['in.vintage_res'].map(vintage_mapping)\n",
    "    mapped_df['in.cooling_setpoint_res'] = mapped_df['in.cooling_setpoint_res'].apply(lambda x: str(x)+\"F\").astype(str)\n",
    "    mapped_df['in.heating_setpoint_res'] = mapped_df['in.heating_setpoint_res'].apply(lambda x: str(x)+\"F\").astype(str)\n",
    "    mapped_df['in.bedrooms_res'] = mapped_df['in.bedrooms_res'].astype(str)\n",
    "\n",
    "    income_mapping = {109999: '100000-119999', 12499: '10000-14999', 64999: '60000-69999', 89999: '80000-99999', \n",
    "                      42499: '40000-44999', 22499: '20000-24999', 47499: '45000-49999', 169999: '160000-179999', \n",
    "                      129999: '120000-139999', 200000: '200000+', 37499: '35000-39999', 54999: '50000-59999', \n",
    "                      32499: '30000-34999', 10000: '<10000', 189999: '180000-199999', 74999: '70000-79999', \n",
    "                      17499: '15000-19999', 27499: '25000-29999', 149999: '140000-159999'}\n",
    "    mapped_df['in.income_res'] = mapped_df['in.income_res'].map(income_mapping)\n",
    "\n",
    "    geometry_mapping = {1749: '1500-1999', 874: '750-999', 1249: '1000-1499', 624: '500-749', 2249: '2000-2499',\n",
    "                        4000: '4000+', 2749: '2500-2999', 3499: '3000-3999', 249: '0-499'}\n",
    "    mapped_df['in.geometry_floor_area_res'] = mapped_df['in.geometry_floor_area_res'].map(geometry_mapping)\n",
    "\n",
    "    return mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAI\\AppData\\Local\\Temp\\ipykernel_4584\\3493477853.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.01 GB\n",
      "Cached memory: 0.02 GB\n",
      "Total memory: 12.00 GB\n",
      "Unused memory: 11.99 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:13<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "def free_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "free_gpu_memory()\n",
    "\n",
    "batch_size = 16\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "input_size, sequence_length = 1, X_res.shape[1]\n",
    "num_classes_categorical = y_res.shape[1]\n",
    "hidden_size = 64\n",
    "num_epochs = 20\n",
    "model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "model = model.to(device)\n",
    "criterion = CustomLoss_res(association_dict_res)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "checkpoint_filename = base_path+ f'/kai/checkpoints/res_model_checkpoint_08_09_22_35.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "best_loss = checkpoint['loss']\n",
    "\n",
    "predictions = []\n",
    "\n",
    "df_test_res = df_test[df_test.building_stock_type == 0]\n",
    "X_test_res, y_pred_res = torch.tensor(df_test_res[df_test_res.columns.difference([\"building_stock_type\"])].values, dtype=torch.float32), df_test_res[\"building_stock_type\"]\n",
    "dataloader = DataLoader(TimeSeriesDataset(X_test_res, torch.zeros(X_test_res.shape[0], y_res.shape[1])), batch_size=16, shuffle=False)\n",
    "\n",
    "print_gpu_memory()\n",
    "for X_batch, y_categorical_batch in tqdm(dataloader):\n",
    "    model.eval()\n",
    "    _X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "    _X_batch = _X_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        categorical_pred = model.predict(_X_batch, association_dict_res)\n",
    "    predictions.append(categorical_pred.cpu())\n",
    "    del _X_batch, categorical_pred\n",
    "    free_gpu_memory()\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "arr_df_res = inverse_process_res(predictions, encoder_res)\n",
    "arr_df_res.index = df_test_res.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in.bedrooms_res\n",
      "['4']\n",
      "in.cooling_setpoint_res\n",
      "['72F']\n",
      "in.heating_setpoint_res\n",
      "['67F']\n",
      "in.geometry_floor_area_res\n",
      "['1500-1999']\n",
      "in.income_res\n",
      "['70000-79999']\n",
      "in.vintage_res\n",
      "['1980s']\n",
      "in.geometry_building_type_recs_res\n",
      "['Single-Family Detached']\n",
      "in.geometry_foundation_type_res\n",
      "['Slab']\n",
      "in.geometry_wall_type_res\n",
      "['Wood Frame']\n",
      "in.heating_fuel_res\n",
      "['Natural Gas']\n",
      "in.roof_material_res\n",
      "['Composition Shingles']\n",
      "in.tenure_res\n",
      "['Renter']\n",
      "in.vacancy_status_res\n",
      "['Occupied']\n"
     ]
    }
   ],
   "source": [
    "for col in arr_df_res.columns:\n",
    "    print(col)\n",
    "    print(arr_df_res[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        building_stock_type in.comstock_building_type_group_com  \\\n",
      "bldg_id                                                           \n",
      "1               residential                                 nan   \n",
      "2               residential                                 nan   \n",
      "3                commercial                          Mercantile   \n",
      "4                commercial                          Mercantile   \n",
      "5               residential                                 nan   \n",
      "...                     ...                                 ...   \n",
      "1436             commercial                          Mercantile   \n",
      "1437            residential                                 nan   \n",
      "1438            residential                                 nan   \n",
      "1439             commercial                          Mercantile   \n",
      "1440            residential                                 nan   \n",
      "\n",
      "        in.heating_fuel_com in.hvac_category_com in.number_of_stories_com  \\\n",
      "bldg_id                                                                     \n",
      "1                       nan                  nan                      nan   \n",
      "2                       nan                  nan                      nan   \n",
      "3               Electricity  Small Packaged Unit                        2   \n",
      "4               Electricity  Small Packaged Unit                        2   \n",
      "5                       nan                  nan                      nan   \n",
      "...                     ...                  ...                      ...   \n",
      "1436            Electricity  Small Packaged Unit                        2   \n",
      "1437                    nan                  nan                      nan   \n",
      "1438                    nan                  nan                      nan   \n",
      "1439            Electricity  Small Packaged Unit                        2   \n",
      "1440                    nan                  nan                      nan   \n",
      "\n",
      "        in.ownership_type_com in.vintage_com in.wall_construction_type_com  \\\n",
      "bldg_id                                                                      \n",
      "1                         nan            nan                           nan   \n",
      "2                         nan            nan                           nan   \n",
      "3                      leased   1980 to 1989                   SteelFramed   \n",
      "4                      leased   1980 to 1989                   SteelFramed   \n",
      "5                         nan            nan                           nan   \n",
      "...                       ...            ...                           ...   \n",
      "1436                   leased   1980 to 1989                   SteelFramed   \n",
      "1437                      nan            nan                           nan   \n",
      "1438                      nan            nan                           nan   \n",
      "1439                   leased   1980 to 1989                   SteelFramed   \n",
      "1440                      nan            nan                           nan   \n",
      "\n",
      "        in.tstat_clg_sp_f..f_com in.tstat_htg_sp_f..f_com  ...  \\\n",
      "bldg_id                                                    ...   \n",
      "1                            nan                      nan  ...   \n",
      "2                            nan                      nan  ...   \n",
      "3                             80                       72  ...   \n",
      "4                             80                       72  ...   \n",
      "5                            nan                      nan  ...   \n",
      "...                          ...                      ...  ...   \n",
      "1436                          80                       72  ...   \n",
      "1437                         nan                      nan  ...   \n",
      "1438                         nan                      nan  ...   \n",
      "1439                          80                       72  ...   \n",
      "1440                         nan                      nan  ...   \n",
      "\n",
      "        in.geometry_building_type_recs_res in.geometry_floor_area_res  \\\n",
      "bldg_id                                                                 \n",
      "1                   Single-Family Detached                  1500-1999   \n",
      "2                   Single-Family Detached                  1500-1999   \n",
      "3                                      nan                        nan   \n",
      "4                                      nan                        nan   \n",
      "5                   Single-Family Detached                  1500-1999   \n",
      "...                                    ...                        ...   \n",
      "1436                                   nan                        nan   \n",
      "1437                Single-Family Detached                  1500-1999   \n",
      "1438                Single-Family Detached                  1500-1999   \n",
      "1439                                   nan                        nan   \n",
      "1440                Single-Family Detached                  1500-1999   \n",
      "\n",
      "        in.geometry_foundation_type_res in.geometry_wall_type_res  \\\n",
      "bldg_id                                                             \n",
      "1                                  Slab                Wood Frame   \n",
      "2                                  Slab                Wood Frame   \n",
      "3                                   nan                       nan   \n",
      "4                                   nan                       nan   \n",
      "5                                  Slab                Wood Frame   \n",
      "...                                 ...                       ...   \n",
      "1436                                nan                       nan   \n",
      "1437                               Slab                Wood Frame   \n",
      "1438                               Slab                Wood Frame   \n",
      "1439                                nan                       nan   \n",
      "1440                               Slab                Wood Frame   \n",
      "\n",
      "        in.heating_fuel_res in.income_res  in.roof_material_res in.tenure_res  \\\n",
      "bldg_id                                                                         \n",
      "1               Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "2               Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "3                       nan           nan                   nan           nan   \n",
      "4                       nan           nan                   nan           nan   \n",
      "5               Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "...                     ...           ...                   ...           ...   \n",
      "1436                    nan           nan                   nan           nan   \n",
      "1437            Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "1438            Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "1439                    nan           nan                   nan           nan   \n",
      "1440            Natural Gas   70000-79999  Composition Shingles        Renter   \n",
      "\n",
      "        in.vacancy_status_res in.vintage_res  \n",
      "bldg_id                                       \n",
      "1                    Occupied          1980s  \n",
      "2                    Occupied          1980s  \n",
      "3                         nan            nan  \n",
      "4                         nan            nan  \n",
      "5                    Occupied          1980s  \n",
      "...                       ...            ...  \n",
      "1436                      nan            nan  \n",
      "1437                 Occupied          1980s  \n",
      "1438                 Occupied          1980s  \n",
      "1439                      nan            nan  \n",
      "1440                 Occupied          1980s  \n",
      "\n",
      "[1440 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_submission(df_com, df_res, df_test, save_filepath=None):\n",
    "\n",
    "    load_filepath_labels = os.path.join(base_path + data_path,'building-instinct-train-label', 'train_label.parquet')\n",
    "\n",
    "    df_targets = pd.read_parquet(load_filepath_labels, engine='pyarrow')\n",
    "    df_targets.sort_index(inplace=True)\n",
    "\n",
    "    bldg_id_list = [i for i in range(1,1441)]\n",
    "\n",
    "    df = pd.DataFrame(index=bldg_id_list, columns=df_targets.columns)\n",
    "    df.index.name = df_targets.index.name\n",
    "\n",
    "    # Populate the first column 'building_stock_type'\n",
    "    df['building_stock_type'] = df_test[\"building_stock_type\"].map({0: 'residential', 1: 'commercial'})\n",
    "\n",
    "    # Separate columns into residential and commercial\n",
    "    res_columns = [col for col in df_targets.columns if col.endswith('_res')]\n",
    "    com_columns = [col for col in df_targets.columns if col.endswith('_com')]\n",
    "\n",
    "    # Populate the rest of the columns based on the value of 'building_stock_type'\n",
    "    for bldg_id in df.index:\n",
    "        if df.at[bldg_id, 'building_stock_type'] == 'residential':\n",
    "            df.loc[bldg_id, com_columns] = np.nan\n",
    "            for col in res_columns:\n",
    "                df.at[bldg_id, col] = df_res.at[bldg_id, col]\n",
    "        else:  # commercial\n",
    "            df.loc[bldg_id, res_columns] = np.nan\n",
    "            for col in com_columns:\n",
    "                df.at[bldg_id, col] = df_com.at[bldg_id, col]\n",
    "    df = df.astype(str)\n",
    "    if save_filepath:\n",
    "        df.to_parquet(save_filepath)\n",
    "    return df\n",
    "\n",
    "df = create_submission(arr_df_com, arr_df_res, df_test, save_filepath=\"submission.parquet\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
