{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.00 GB\n",
      "Cached memory: 0.00 GB\n",
      "Total memory: 12.00 GB\n",
      "Unused memory: 12.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import print_gpu_memory\n",
    "print_gpu_memory()\n",
    "import os\n",
    "import sys\n",
    "base_path = r\"C:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\"\n",
    "data_path = r\"\\data\\building-instinct-starter-notebook\\Starter notebook\"\n",
    "sys.path.append(base_path+data_path)\n",
    "sys.path.append(base_path+\"\\kai\")\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import (calculate_average_hourly_energy_consumption, train_model, get_pred, calculate_hierarchical_f1_score,\n",
    "sample_submission_generator)\n",
    "from preprocessing import Preprocessor\n",
    "# file_path = base_path + data_path + r\"\\building-instinct-train-data\"\n",
    "# df_features = Preprocessor.load_standard_df(file_path)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/data_9000.parquet', engine='pyarrow')\n",
    "\n",
    "# df_loaded_1 = pd.read_parquet(base_path + '/preprocessed_data/data_3000.parquet', engine='pyarrow')\n",
    "# df_loaded_2 = pd.read_parquet(base_path + '/preprocessed_data/data_6000.parquet', engine='pyarrow')\n",
    "# df_loaded_3 = pd.read_parquet(base_path + '/preprocessed_data/data_9000.parquet', engine='pyarrow')\n",
    "\n",
    "# df_features = pd.concat([df_loaded_1, df_loaded_2, df_loaded_3], axis=0)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "\n",
    "df_features = pd.read_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "df_features.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import TargetPreprocessor\n",
    "load_filepath_labels = os.path.join(base_path + data_path,'building-instinct-train-label', 'train_label.parquet')#path to the train label file\n",
    "df_targets = pd.read_parquet(load_filepath_labels, engine='pyarrow')\n",
    "df_targets.sort_index(inplace=True)\n",
    "\n",
    "df_targets_res = df_targets[df_targets.building_stock_type == \"residential\"].filter(like='_res').copy()\n",
    "df_targets_com = df_targets[df_targets.building_stock_type == \"commercial\"].filter(like='_com').copy()\n",
    "target_preprocessor = TargetPreprocessor()\n",
    "df_targets_res, association_dict_res, encoder_res = target_preprocessor.preprocess_res(df_targets_res)\n",
    "df_targets_com, association_dict_com, encoder_com = target_preprocessor.preprocess_com(df_targets_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = df_features.index.intersection(df_targets_com.index)\n",
    "# Filter the data\n",
    "X_com = df_features[df_features.index.isin(common_indices)]\n",
    "X_com = torch.tensor(X_com.values, dtype=torch.float32)\n",
    "y_com = df_targets_com[df_targets_com.index.isin(common_indices)]\n",
    "y_com = torch.tensor(y_com.values, dtype=torch.float32)\n",
    "\n",
    "X_res = df_features[df_features.index.isin(df_targets_res.index)]\n",
    "X_res = torch.tensor(X_res.values, dtype=torch.float32)\n",
    "y_res = df_targets_res[df_targets_res.index.isin(df_features.index)]\n",
    "y_res = torch.tensor(y_res.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992323346090601\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = df_features, df_targets[\"building_stock_type\"].map({\"residential\": 0, \"commercial\": 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = Pipeline([('preprocessor', ColumnTransformer([\n",
    "            ('scaler', StandardScaler(), X.columns),\n",
    "            ('encoder', OneHotEncoder(), [])\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f1_score(y_test, y_pred, average='macro'))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "df_test.sort_index(inplace=True)\n",
    "\n",
    "clf = Pipeline([('preprocessor', ColumnTransformer([\n",
    "            ('scaler', StandardScaler(), X.columns),\n",
    "            ('encoder', OneHotEncoder(), [])\n",
    "        ])),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(df_test)\n",
    "df_test[\"building_stock_type\"] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## com model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from models import MultiTaskLSTM, CustomLoss, TimeSeriesDataset\n",
    "# from datetime import datetime\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # model parameters\n",
    "# batch_size = 16\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# input_size, sequence_length = 1, X_com.shape[1]\n",
    "# num_classes_categorical = y_com.shape[1]\n",
    "# hidden_size = 64\n",
    "# num_epochs = 20\n",
    "\n",
    "# weight_numerical = 10e-4\n",
    "# weight_categorical = 1.0\n",
    "\n",
    "# best_combined_loss = float('inf')\n",
    "# checkpoint_filename = base_path+ f'/kai/checkpoints/model_checkpoint_{datetime.now().strftime(\"%m_%d_%H_%M\")}.pth.tar'\n",
    "\n",
    "# # create dataloaders\n",
    "# dataloader_com = DataLoader(TimeSeriesDataset(X_com, y_com), batch_size=batch_size, shuffle=True)\n",
    "# dataloader_res = DataLoader(TimeSeriesDataset(X_res, y_res), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "# model = model.to(device)\n",
    "# criterion = CustomLoss(association_dict_com)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     for X_batch, y_categorical_batch in dataloader_com:\n",
    "#         X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "#         X_batch = X_batch.to(device)\n",
    "#         y_categorical_batch = y_categorical_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         categorical_pred = model(X_batch)\n",
    "#         loss, loss_numerical, loss_categorical = criterion(categorical_pred, y_categorical_batch)\n",
    "        \n",
    "#         # Combine losses with adjusted weights\n",
    "#         combined_loss = weight_numerical * loss_numerical + weight_categorical * loss_categorical\n",
    "\n",
    "#         combined_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "#                   f'Total Loss: {loss.item():.4f}, '\n",
    "#                   f'Numerical Loss: {loss_numerical.item():.4f}, '\n",
    "#                   f'Categorical Loss: {loss_categorical.item():.4f}, '\n",
    "#                   f'Combined Loss: {combined_loss.item():.4f}, '\n",
    "#                   f'weights: {weight_numerical:.4f}, {weight_categorical:.4f}')\n",
    "    \n",
    "#     if combined_loss.item() < best_combined_loss:\n",
    "#         torch.save({'epoch': epoch + 1,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'loss': combined_loss.item(),}, checkpoint_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAI\\AppData\\Local\\Temp\\ipykernel_14864\\3095246467.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2376e+00, 1.9897e+03, 3.5269e+02, 3.4938e+02, 8.7197e+00, 1.8646e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2499e+00, 1.9759e+03, 3.5024e+02, 3.4684e+02, 8.7135e+00, 1.8552e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2634e+00, 1.9178e+03, 3.3992e+02, 3.3631e+02, 8.6316e+00, 1.8104e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5269e+02, 3.4938e+02, 8.7197e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2439e+00, 1.9825e+03, 3.5141e+02, 3.4805e+02, 8.7163e+00, 1.8597e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5269e+02, 3.4938e+02, 8.7197e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5270e+02, 3.4938e+02, 8.7198e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2376e+00, 1.9897e+03, 3.5269e+02, 3.4938e+02, 8.7197e+00, 1.8647e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2738e+00, 1.9269e+03, 3.4154e+02, 3.3792e+02, 8.6654e+00, 1.8192e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2379e+00, 1.9893e+03, 3.5263e+02, 3.4931e+02, 8.7195e+00, 1.8644e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2388e+00, 1.9882e+03, 3.5242e+02, 3.4910e+02, 8.7189e+00, 1.8636e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2525e+00, 1.9730e+03, 3.4973e+02, 3.4631e+02, 8.7122e+00, 1.8533e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2377e+00, 1.9897e+03, 3.5269e+02, 3.4937e+02, 8.7197e+00, 1.8646e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2399e+00, 1.9869e+03, 3.5220e+02, 3.4887e+02, 8.7183e+00, 1.8627e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2792e+00, 1.9323e+03, 3.4251e+02, 3.3888e+02, 8.6820e+00, 1.8243e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00],\n",
      "        [2.2465e+00, 1.9796e+03, 3.5090e+02, 3.4753e+02, 8.7151e+00, 1.8578e+01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0000e+00, 0.0000e+00]], device='cuda:0', grad_fn=<CopySlices>)\n",
      "tensor([1.0000e+00, 1.9400e+03, 7.5000e+01, 6.8000e+01, 6.7500e+00, 1.1750e+01,\n",
      "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from models import MultiTaskLSTM, CustomLoss, TimeSeriesDataset\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size, input_size, sequence_length, hidden_size, num_classes_categorical = 16, 1, X_com.shape[1], 64, y_com.shape[1]\n",
    "checkpoint_filename = base_path+ f'/kai/checkpoints/com_model_checkpoint_08_06_14_49.pth.tar'\n",
    "\n",
    "dataloader_com = DataLoader(TimeSeriesDataset(X_com, y_com), batch_size=batch_size, shuffle=True)\n",
    "model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "for X_batch, y_categorical_batch in dataloader_com:\n",
    "    for i in [0, 1]:\n",
    "        _X_batch = X_batch[:, :].view(X_batch.shape[0], sequence_length, input_size)\n",
    "        _X_batch = _X_batch.to(device)\n",
    "        categorical_pred = model.predict(_X_batch, association_dict_com)\n",
    "        print(categorical_pred)\n",
    "        print(y_categorical_batch[i, :])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the original com df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in.number_of_stories_com</th>\n",
       "      <th>in.vintage_com</th>\n",
       "      <th>in.tstat_clg_sp_f..f_com</th>\n",
       "      <th>in.tstat_htg_sp_f..f_com</th>\n",
       "      <th>in.weekday_opening_time..hr_com</th>\n",
       "      <th>in.weekday_operating_hours..hr_com</th>\n",
       "      <th>in.comstock_building_type_group_com</th>\n",
       "      <th>in.heating_fuel_com</th>\n",
       "      <th>in.hvac_category_com</th>\n",
       "      <th>in.ownership_type_com</th>\n",
       "      <th>in.wall_construction_type_com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1970 to 1979</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Office</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1970 to 1979</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>1980 to 1989</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>Before 1946</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.25</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>1970 to 1979</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>8.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>Mercantile</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>Small Packaged Unit</td>\n",
       "      <td>leased</td>\n",
       "      <td>SteelFramed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    in.number_of_stories_com in.vintage_com  in.tstat_clg_sp_f..f_com  \\\n",
       "0                          2   1980 to 1989                        80   \n",
       "1                          2   1970 to 1979                        80   \n",
       "2                          2    Before 1946                        80   \n",
       "3                          2   1980 to 1989                        80   \n",
       "4                          2   1980 to 1989                        80   \n",
       "5                          2   1980 to 1989                        80   \n",
       "6                          2   1980 to 1989                        80   \n",
       "7                          2   1980 to 1989                        80   \n",
       "8                          2    Before 1946                        80   \n",
       "9                          2   1980 to 1989                        80   \n",
       "10                         2   1980 to 1989                        80   \n",
       "11                         2   1970 to 1979                        80   \n",
       "12                         2   1980 to 1989                        80   \n",
       "13                         2   1980 to 1989                        80   \n",
       "14                         2    Before 1946                        80   \n",
       "15                         2   1970 to 1979                        80   \n",
       "\n",
       "    in.tstat_htg_sp_f..f_com in.weekday_opening_time..hr_com  \\\n",
       "0                         72                            8.75   \n",
       "1                         72                            8.75   \n",
       "2                         72                            8.75   \n",
       "3                         72                            8.75   \n",
       "4                         72                            8.75   \n",
       "5                         72                            8.75   \n",
       "6                         72                            8.75   \n",
       "7                         72                            8.75   \n",
       "8                         72                            8.75   \n",
       "9                         72                            8.75   \n",
       "10                        72                            8.75   \n",
       "11                        72                            8.75   \n",
       "12                        72                            8.75   \n",
       "13                        72                            8.75   \n",
       "14                        72                            8.75   \n",
       "15                        72                            8.75   \n",
       "\n",
       "   in.weekday_operating_hours..hr_com in.comstock_building_type_group_com  \\\n",
       "0                               18.75                          Mercantile   \n",
       "1                                18.5                          Mercantile   \n",
       "2                                18.0                              Office   \n",
       "3                               18.75                          Mercantile   \n",
       "4                                18.5                          Mercantile   \n",
       "5                               18.75                          Mercantile   \n",
       "6                               18.75                          Mercantile   \n",
       "7                               18.75                          Mercantile   \n",
       "8                               18.25                              Office   \n",
       "9                               18.75                          Mercantile   \n",
       "10                              18.75                          Mercantile   \n",
       "11                               18.5                          Mercantile   \n",
       "12                              18.75                          Mercantile   \n",
       "13                              18.75                          Mercantile   \n",
       "14                              18.25                          Mercantile   \n",
       "15                               18.5                          Mercantile   \n",
       "\n",
       "   in.heating_fuel_com in.hvac_category_com in.ownership_type_com  \\\n",
       "0          Electricity  Small Packaged Unit                leased   \n",
       "1          Electricity  Small Packaged Unit                leased   \n",
       "2          Electricity  Small Packaged Unit                leased   \n",
       "3          Electricity  Small Packaged Unit                leased   \n",
       "4          Electricity  Small Packaged Unit                leased   \n",
       "5          Electricity  Small Packaged Unit                leased   \n",
       "6          Electricity  Small Packaged Unit                leased   \n",
       "7          Electricity  Small Packaged Unit                leased   \n",
       "8          Electricity  Small Packaged Unit                leased   \n",
       "9          Electricity  Small Packaged Unit                leased   \n",
       "10         Electricity  Small Packaged Unit                leased   \n",
       "11         Electricity  Small Packaged Unit                leased   \n",
       "12         Electricity  Small Packaged Unit                leased   \n",
       "13         Electricity  Small Packaged Unit                leased   \n",
       "14         Electricity  Small Packaged Unit                leased   \n",
       "15         Electricity  Small Packaged Unit                leased   \n",
       "\n",
       "   in.wall_construction_type_com  \n",
       "0                    SteelFramed  \n",
       "1                    SteelFramed  \n",
       "2                    SteelFramed  \n",
       "3                    SteelFramed  \n",
       "4                    SteelFramed  \n",
       "5                    SteelFramed  \n",
       "6                    SteelFramed  \n",
       "7                    SteelFramed  \n",
       "8                    SteelFramed  \n",
       "9                    SteelFramed  \n",
       "10                   SteelFramed  \n",
       "11                   SteelFramed  \n",
       "12                   SteelFramed  \n",
       "13                   SteelFramed  \n",
       "14                   SteelFramed  \n",
       "15                   SteelFramed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from postprocessing import inverse_process\n",
    "arr_df = inverse_process(categorical_pred, encoder_com) # todo: standardize the target numerical columns in preprocessing\n",
    "display(arr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = base_path + data_path + r\"\\building-instinct-test-data\"\n",
    "# df_features = Preprocessor.load_standard_df(file_path)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# df_features.to_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "\n",
    "df_test = pd.read_parquet(base_path + '/preprocessed_data/data_test.parquet', engine='pyarrow')\n",
    "df_test.sort_index(inplace=True)\n",
    "\n",
    "# TODO: clf that predicts com or res\n",
    "# then filter by com & res\n",
    "\n",
    "df_test = df_test[df_test.index.isin(df_features.index)]\n",
    "X_test_com = torch.tensor(df_test.values, dtype=torch.float32)\n",
    "# X_test_com = X_test_com.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAI\\AppData\\Local\\Temp\\ipykernel_14864\\934529602.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory: 0.02 GB\n",
      "Cached memory: 10.16 GB\n",
      "Total memory: 12.00 GB\n",
      "Unused memory: 11.98 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:24<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "def free_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "free_gpu_memory()\n",
    "model = MultiTaskLSTM(input_size, hidden_size, num_classes_categorical)\n",
    "model = model.to(device)\n",
    "criterion = CustomLoss(association_dict_com)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "checkpoint_filename = base_path+ f'/kai/checkpoints/com_model_checkpoint_08_06_14_49.pth.tar'\n",
    "checkpoint = torch.load(checkpoint_filename)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "best_loss = checkpoint['loss']\n",
    "\n",
    "predictions = []\n",
    "dataloader = DataLoader(TimeSeriesDataset(X_test_com, torch.zeros(X_test_com.shape[0], y_com.shape[1])), batch_size=16, shuffle=False)\n",
    "\n",
    "print_gpu_memory()\n",
    "for X_batch, y_categorical_batch in tqdm(dataloader):\n",
    "    model.eval()\n",
    "    _X_batch = X_batch.view(X_batch.shape[0], sequence_length, input_size)\n",
    "    _X_batch = _X_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        categorical_pred = model.predict(_X_batch, association_dict_com)\n",
    "    predictions.append(categorical_pred.cpu())\n",
    "    del _X_batch, categorical_pred\n",
    "    free_gpu_memory()\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "arr_df = inverse_process(predictions, encoder_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "['Before 1946' '1980 to 1989' '1960 to 1969' '1970 to 1979' '1946 to 1959']\n",
      "[80]\n",
      "[72]\n",
      "[8.5 8.75]\n",
      "[18.0 18.75 18.5 18.25]\n",
      "['Office' 'Mercantile']\n",
      "['Electricity']\n",
      "['Small Packaged Unit']\n",
      "['leased']\n",
      "['SteelFramed']\n"
     ]
    }
   ],
   "source": [
    "for col in arr_df.columns:\n",
    "    print(arr_df[col].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
