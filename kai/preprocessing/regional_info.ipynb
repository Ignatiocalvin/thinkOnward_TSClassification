{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Import the data sets\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "base_path = r\"C:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\"\n",
    "data_path = r\"\\data\\building-instinct-starter-notebook\\Starter notebook\"\n",
    "preprocessing_path = r\"\\kai\\preprocessing\"\n",
    "sys.path.append(base_path+data_path)\n",
    "sys.path.append(base_path+\"\\kai\")\n",
    "sys.path.append(base_path+preprocessing_path)\n",
    "from preprocessing import Preprocessor\n",
    "\n",
    "# df_features_dict = {}\n",
    "\n",
    "# for s in [\"monthly\", \"weekly\", \"daily\"]:\n",
    "#     # df_features = pd.read_parquet(base_path + f'/preprocessed_data/{s}_data.parquet', engine='pyarrow')\n",
    "#     folder_path = os.path.join(os.getcwd(),'building-instinct-train-data')# folder path for the train dataset\n",
    "#     df_features = Preprocessor.calculate_average_energy_consumption(folder_path, type=\"daily\")\n",
    "#     # df_features.sort_index(inplace=True)\n",
    "#     # df_features_dict[s] = df_features\n",
    "\n",
    "# # Full Dataset\n",
    "# df_features_full = pd.read_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "# df_features_full.sort_index(inplace=True)\n",
    "# df_features_dict['full'] = df_features_full\n",
    "\n",
    "# # Labels\n",
    "# load_filepath_labels = os.path.join(base_path + data_path,'building-instinct-train-label', 'train_label.parquet')#path to the train label file\n",
    "# df_targets = pd.read_parquet(load_filepath_labels, engine='pyarrow')\n",
    "# y = df_targets[\"building_stock_type\"].map({\"residential\": 0, \"commercial\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KY']\n",
      "KY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.path.join(base_path + data_path,'building-instinct-train-data')\n",
    "for file_name in tqdm(os.listdir(folder_path)[:1]):\n",
    "    if file_name.endswith(\".parquet\"):\n",
    "        # Extract the bldg_id from the file name\n",
    "        bldg_id = int(file_name.split('.')[0])\n",
    "\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Read the original parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        # Convert 'timestamp' column to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(df[\"in.state\"].unique())\n",
    "        s = df[\"in.state\"].unique()[0]\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_energy_consumption(folder_path, season_months_dict=None, type='daily', with_regional=False):\n",
    "    \"\"\"\n",
    "    Process multiple parquet files in a folder, calculate average energy consumption,\n",
    "    and return a pandas DataFrame with each row corresponding to one file in the folder.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing parquet files.\n",
    "    - season_months_dict (dict): A dictionary where keys are season names (strings) and values are lists\n",
    "    of corresponding month numbers. For example, {'cold': [1, 2, 12], 'hot': [6, 7, 8], 'mild': [3, 4, 5, 9, 10, 11]}.\n",
    "\n",
    "    Returns:\n",
    "    - df_ave (pd.DataFrame): A pandas DataFrame with each row corresponding to one file in the folder (i.e. one building).\n",
    "    The columns are multi-layer with the first layer being the day/week/month/season and the second layer the hour of the day \n",
    "    Index ('bldg_id') contains building IDs. Column values are average hourly electricity energy consumption\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store individual DataFrames for each file\n",
    "    result_dfs = []\n",
    "    if with_regional:\n",
    "        locations = {\n",
    "            \"WI\": {\"latitude\": 44.500000, \"longitude\": -89.500000},  # Wisconsin\n",
    "            \"WV\": {\"latitude\": 39.000000, \"longitude\": -80.500000},  # West Virginia\n",
    "            \"VT\": {\"latitude\": 44.000000, \"longitude\": -72.699997},  # Vermont\n",
    "            \"TX\": {\"latitude\": 31.000000, \"longitude\": -100.000000}, # Texas\n",
    "            \"SD\": {\"latitude\": 44.500000, \"longitude\": -100.000000}, # South Dakota\n",
    "            \"RI\": {\"latitude\": 41.742325, \"longitude\": -71.742332},  # Rhode Island\n",
    "            \"OR\": {\"latitude\": 44.000000, \"longitude\": -120.500000}, # Oregon\n",
    "            \"NY\": {\"latitude\": 43.000000, \"longitude\": -75.000000},  # New York\n",
    "            \"NH\": {\"latitude\": 44.000000, \"longitude\": -71.500000},  # New Hampshire\n",
    "            \"NE\": {\"latitude\": 41.500000, \"longitude\": -100.000000}, # Nebraska\n",
    "            \"KS\": {\"latitude\": 38.500000, \"longitude\": -98.000000},  # Kansas\n",
    "            \"MS\": {\"latitude\": 33.000000, \"longitude\": -90.000000},  # Mississippi\n",
    "            \"IL\": {\"latitude\": 40.000000, \"longitude\": -89.000000},  # Illinois\n",
    "            \"DE\": {\"latitude\": 39.000000, \"longitude\": -75.500000},  # Delaware\n",
    "            \"CT\": {\"latitude\": 41.599998, \"longitude\": -72.699997},  # Connecticut\n",
    "            \"AR\": {\"latitude\": 34.799999, \"longitude\": -92.199997},  # Arkansas\n",
    "            \"IN\": {\"latitude\": 40.273502, \"longitude\": -86.126976},  # Indiana\n",
    "            \"MO\": {\"latitude\": 38.573936, \"longitude\": -92.603760},  # Missouri\n",
    "            \"FL\": {\"latitude\": 27.994402, \"longitude\": -81.760254},  # Florida\n",
    "            \"NV\": {\"latitude\": 39.876019, \"longitude\": -117.224121}, # Nevada\n",
    "            \"ME\": {\"latitude\": 45.367584, \"longitude\": -68.972168},  # Maine\n",
    "            \"MI\": {\"latitude\": 44.182205, \"longitude\": -84.506836},  # Michigan\n",
    "            \"GA\": {\"latitude\": 33.247875, \"longitude\": -83.441162},  # Georgia\n",
    "            \"HI\": {\"latitude\": 19.741755, \"longitude\": -155.844437}, # Hawaii\n",
    "            \"AK\": {\"latitude\": 66.160507, \"longitude\": -153.369141}, # Alaska\n",
    "            \"TN\": {\"latitude\": 35.860119, \"longitude\": -86.660156},  # Tennessee\n",
    "            \"VA\": {\"latitude\": 37.926868, \"longitude\": -78.024902},  # Virginia\n",
    "            \"NJ\": {\"latitude\": 39.833851, \"longitude\": -74.871826},  # New Jersey\n",
    "            \"KY\": {\"latitude\": 37.839333, \"longitude\": -84.270020},  # Kentucky\n",
    "            \"ND\": {\"latitude\": 47.650589, \"longitude\": -100.437012}, # North Dakota\n",
    "            \"MN\": {\"latitude\": 46.392410, \"longitude\": -94.636230},  # Minnesota\n",
    "            \"OK\": {\"latitude\": 36.084621, \"longitude\": -96.921387},  # Oklahoma\n",
    "            \"MT\": {\"latitude\": 46.965260, \"longitude\": -109.533691}, # Montana\n",
    "            \"WA\": {\"latitude\": 47.751076, \"longitude\": -120.740135}, # Washington\n",
    "            \"UT\": {\"latitude\": 39.419220, \"longitude\": -111.950684}, # Utah\n",
    "            \"CO\": {\"latitude\": 39.113014, \"longitude\": -105.358887}, # Colorado\n",
    "            \"OH\": {\"latitude\": 40.367474, \"longitude\": -82.996216},  # Ohio\n",
    "            \"AL\": {\"latitude\": 32.318230, \"longitude\": -86.902298},  # Alabama\n",
    "            \"IA\": {\"latitude\": 42.032974, \"longitude\": -93.581543},  # Iowa\n",
    "            \"NM\": {\"latitude\": 34.307144, \"longitude\": -106.018066}, # New Mexico\n",
    "            \"SC\": {\"latitude\": 33.836082, \"longitude\": -81.163727},  # South Carolina\n",
    "            \"PA\": {\"latitude\": 41.203323, \"longitude\": -77.194527},  # Pennsylvania\n",
    "            \"AZ\": {\"latitude\": 34.048927, \"longitude\": -111.093735}, # Arizona\n",
    "            \"MD\": {\"latitude\": 39.045753, \"longitude\": -76.641273},  # Maryland\n",
    "            \"MA\": {\"latitude\": 42.407211, \"longitude\": -71.382439},  # Massachusetts\n",
    "            \"CA\": {\"latitude\": 36.778259, \"longitude\": -119.417931}, # California\n",
    "            \"ID\": {\"latitude\": 44.068203, \"longitude\": -114.742043}, # Idaho\n",
    "            \"WY\": {\"latitude\": 43.075970, \"longitude\": -107.290283}, # Wyoming\n",
    "            \"NC\": {\"latitude\": 35.782169, \"longitude\": -80.793457},  # North Carolina\n",
    "            \"LA\": {\"latitude\": 30.391830, \"longitude\": -92.329102},  # Louisiana\n",
    "            \"DC\": {\"latitude\": 38.907200, \"longitude\": -77.036900},  # Washington, D.C.\n",
    "        }\n",
    "\n",
    "    # Iterate through all files in the folder_path\n",
    "    for file_name in tqdm(os.listdir(folder_path)):\n",
    "        if file_name.endswith(\".parquet\"):\n",
    "            # Extract the bldg_id from the file name\n",
    "            bldg_id = int(file_name.split('.')[0])\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "            # Read the original parquet file\n",
    "            df = pd.read_parquet(file_path)\n",
    "\n",
    "            # Convert 'timestamp' column to datetime\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df['hour'] = df['timestamp'].dt.hour\n",
    "            if with_regional:\n",
    "                state = df[\"in.state\"].unique()[0]\n",
    "                latitude = locations[state][\"latitude\"]\n",
    "                longitude = locations[state][\"longitude\"]\n",
    "            if type == 'daily':# -> goes from Input: 365 * 24 * 4 = 35,040 columns to 365 * 24 = 8,760 values per building\n",
    "                df['day_of_year'] = df['timestamp'].dt.day_of_year\n",
    "                df['hourly_energy_consumption'] = df.groupby(['day_of_year', 'hour'])['out.electricity.total.energy_consumption'].transform('mean')\n",
    "                result_df = df.pivot_table(values='hourly_energy_consumption', index='bldg_id', columns=['day_of_year', 'hour'])\n",
    "            \n",
    "            elif type == 'weekly':# -> goes from Input: 365 * 24 * 4 = 35,040 columns to 52 * 24 = 1,248 values per building\n",
    "                df['week'] = df['timestamp'].dt.isocalendar().week\n",
    "                df['weekly_energy_consumption'] = df.groupby(['week', 'hour'])['out.electricity.total.energy_consumption'].transform('mean')\n",
    "                result_df = df.pivot_table(values='weekly_energy_consumption', index='bldg_id', columns=['week', 'hour'])\n",
    "\n",
    "            elif type == 'monthly':# -> goes from Input: 365 * 24 * 4 = 35,040 columns to 12 * 24 = 288 values per building\n",
    "                df['month'] = df['timestamp'].dt.month\n",
    "                df['monthly_energy_consumption'] = df.groupby(['month', 'hour'])['out.electricity.total.energy_consumption'].transform('mean')\n",
    "                result_df = df.pivot_table(values='monthly_energy_consumption', index='bldg_id', columns=['month', 'hour'])\n",
    "\n",
    "            elif type == 'seasonal': # originally provided prerpocessing method -> goes from Input: 365 * 24 * 4 = 35,040 columns to 365 * (12/s)  = ... values per building\n",
    "                df['month'] = df['timestamp'].dt.month\n",
    "                # Create a mapping from month to the corresponding season\n",
    "                month_to_season = {month: season for season, months_list in season_months_dict.items() for month in months_list}\n",
    "\n",
    "                # Assign a season to each row based on the month\n",
    "                df['season'] = df['month'].map(month_to_season)\n",
    "\n",
    "                # Calculate hourly average energy consumption for each row\n",
    "                df['hourly_avg_energy_consumption'] = 4 * df.groupby(['season', 'hour'])['out.electricity.total.energy_consumption'].transform('mean')\n",
    "\n",
    "                # Pivot the dataframe to create the desired output format\n",
    "                result_df = df.pivot_table(values='hourly_avg_energy_consumption', index='bldg_id', columns=['season', 'hour'])\n",
    "\n",
    "                # Reset the column names\n",
    "                result_df.columns = pd.MultiIndex.from_tuples([(season, hour+1) for season, months_list in season_months_dict.items() for hour in range(24)])\n",
    "            else:\n",
    "                raise ValueError('Invalid type. Please select from hourly, weekly, or monthly.')\n",
    "\n",
    "            # Add 'bldg_id' index with values corresponding to the names of the parquet files\n",
    "            result_df['bldg_id'] = bldg_id\n",
    "            if with_regional:\n",
    "                result_df[\"latitude\"] = latitude\n",
    "                result_df[\"longitude\"] = longitude\n",
    "            result_df.set_index('bldg_id', inplace=True)\n",
    "\n",
    "            # Append the result_df to the list\n",
    "            result_dfs.append(result_df)\n",
    "\n",
    "    # Concatenate all individual DataFrames into a single DataFrame\n",
    "    df_ave = pd.concat(result_dfs, ignore_index=False)\n",
    "\n",
    "    return df_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7200/7200 [04:53<00:00, 24.53it/s]\n",
      "c:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:159: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n",
      "100%|██████████| 7200/7200 [05:53<00:00, 20.36it/s]\n",
      "c:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:159: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n",
      "100%|██████████| 7200/7200 [07:55<00:00, 15.14it/s]\n",
      "c:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:159: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# folder_path = os.path.join(base_path + data_path,'building-instinct-train-data')\n",
    "# df_features = calculate_average_energy_consumption(folder_path, type=\"monthly\", with_regional=True)\n",
    "# df_features.sort_index(inplace=True)\n",
    "# print(df_features)\n",
    "\n",
    "\n",
    "for s in [\"monthly\", \"weekly\", \"daily\"]:\n",
    "    save_path = os.path.join(base_path + f'/preprocessed_data/with_regional/{s}_data.parquet')\n",
    "    # df_features = pd.read_parquet(base_path + f'/preprocessed_data/{s}_data.parquet', engine='pyarrow')\n",
    "    folder_path = os.path.join(base_path + data_path,'building-instinct-train-data')\n",
    "    df_features = calculate_average_energy_consumption(folder_path, type=s, with_regional=True)\n",
    "    df_features.sort_index(inplace=True)\n",
    "    df_features.to_parquet(save_path, engine='pyarrow')\n",
    "\n",
    "df_features_full = pd.read_parquet(base_path + '/preprocessed_data/standard_data.parquet', engine='pyarrow')\n",
    "df_features_full.sort_index(inplace=True)\n",
    "df_features_full[\"latitude\"] = df_features[\"latitude\"]\n",
    "df_features_full[\"longitude\"] = df_features[\"longitude\"]\n",
    "save_path = os.path.join(base_path + f'/preprocessed_data/with_regional/standard_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KAI\\Coding\\ThinkOnward_challenge\\thinkOnward_TSClassification\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:159: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_features_full.to_parquet(save_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "CA    792\n",
      "TX    551\n",
      "FL    507\n",
      "NY    431\n",
      "PA    313\n",
      "IL    297\n",
      "OH    295\n",
      "NC    238\n",
      "MI    222\n",
      "GA    221\n",
      "VA    202\n",
      "NJ    186\n",
      "IN    175\n",
      "MO    169\n",
      "TN    166\n",
      "WA    153\n",
      "MA    146\n",
      "CO    143\n",
      "WI    140\n",
      "MD    138\n",
      "AL    126\n",
      "SC    123\n",
      "LA    113\n",
      "MN    112\n",
      "AZ    108\n",
      "OK     89\n",
      "KY     87\n",
      "OR     86\n",
      "MS     79\n",
      "CT     72\n",
      "AR     69\n",
      "NV     65\n",
      "IA     61\n",
      "UT     56\n",
      "NM     53\n",
      "KS     49\n",
      "NE     44\n",
      "ME     41\n",
      "ID     41\n",
      "WV     37\n",
      "NH     32\n",
      "MT     30\n",
      "RI     28\n",
      "DE     27\n",
      "DC     18\n",
      "WY     18\n",
      "ND     14\n",
      "AK     11\n",
      "SD      9\n",
      "HI      9\n",
      "VT      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_features.state.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
